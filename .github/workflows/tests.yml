name: Multi-software test

on:
  pull_request:
  push:
    branches:
    - master
    - develop

env:
  YDATA_PROFILING_NO_ANALYTICS: false

jobs:
  test:
    name: Tests
    strategy:
      matrix:
        os: [ ubuntu-22.04 ]
        python-version: ["3.9", "3.10", "3.11", "3.12" ]
        pandas: [ "pandas>1.1" ]
        numpy: [ "numpy>=1.21" ]
    runs-on: ${{ matrix.os }}

    steps:
    - uses: actions/checkout@v4
    
    - name: Setup python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        architecture: x64
    
    - uses: actions/cache@v4
      if: startsWith(runner.os, 'Linux')
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-${{ matrix.pandas }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-${{ matrix.pandas }}-pip-
    - uses: actions/cache@v4
      if: startsWith(runner.os, 'macOS')
      with:
        path: ~/Library/Caches/pip
        key: ${{ runner.os }}-${{ matrix.pandas }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-${{ matrix.pandas }}-pip-
    - uses: actions/cache@v4
      if: startsWith(runner.os, 'Windows')
      with:
        path: ~\AppData\Local\pip\Cache
        key: ${{ runner.os }}-${{ matrix.pandas }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-${{ matrix.pandas }}-pip-
    - run: |
        pip install --upgrade pip setuptools wheel
        pip install ".[test]" "${{ matrix.pandas }}" "${{ matrix.numpy }}"
    - run: echo "YDATA_PROFILING_NO_ANALYTICS=False" >> $GITHUB_ENV
    - run: make install

    - run: make test

  coverage:
    name: Coverage
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-22.04]
        python-version: ["3.12"]
        pandas: [ "pandas>1.1" ]
        numpy: [ "numpy>=1.21" ]

    steps:
    - uses: actions/checkout@v4

    - name: Setup python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        architecture: x64

    - uses: actions/cache@v4
      if: startsWith(runner.os, 'Linux')
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-${{ matrix.pandas }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-${{ matrix.pandas }}-pip-
    - uses: actions/cache@v4
      if: startsWith(runner.os, 'macOS')
      with:
        path: ~/Library/Caches/pip
        key: ${{ runner.os }}-${{ matrix.pandas }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-${{ matrix.pandas }}-pip-
    - uses: actions/cache@v4
      if: startsWith(runner.os, 'Windows')
      with:
        path: ~\AppData\Local\pip\Cache
        key: ${{ runner.os }}-${{ matrix.pandas }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-${{ matrix.pandas }}-pip-
    - run: |
        pip install --upgrade pip setuptools wheel
        pip install ".[test]" "${{ matrix.pandas }}" "${{ matrix.numpy }}"
        echo "YDATA_PROFILING_NO_ANALYTICS=False" >> $GITHUB_ENV
    - run: make install

    - run: make test_cov

    - uses: actions/cache@v4
      if: startsWith(runner.os, 'Windows')
      with:
        path: ~\AppData\Local\pip\Cache
        key: ${{ runner.os }}-${{ matrix.pandas }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-${{ matrix.pandas }}-pip-
    - run: |
        pip install --upgrade pip setuptools wheel
        pip install ".[test]" "${{ matrix.pandas }}" "${{ matrix.numpy }}"
    - run: make install
    - run: make test_cov
    - run: codecov -F py${{ matrix.python-version }}-${{ matrix.os }}-${{ matrix.pandas }}-${{ matrix.numpy }}

  test_spark:
    runs-on: ubuntu-24.04
    continue-on-error: false
    strategy:
      matrix:
        python-version: [ "3.9", "3.10", "3.11", "3.12" ]
        pyspark-version: [ "3.4" , "3.5" ]

    name: Tests Spark | Python ${{ matrix.python-version }} | PySpark ${{ matrix.pyspark-version }}

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Install Java (OpenJDK 11)
        run: |
          sudo apt-get update
          sudo apt-get install -y openjdk-11-jdk
          echo "JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64" >> $GITHUB_ENV
          echo "PATH=$JAVA_HOME/bin:$PATH" >> $GITHUB_ENV
          java -version

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          architecture: x64

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ matrix.python-version }}-${{ matrix.pyspark-version }}-${{ hashFiles('requirements/*.txt', 'setup.cfg', 'pyproject.toml') }}
          restore-keys: |
            pip-${{ runner.os }}-

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install pyarrow>4.0.0 pyspark=="${{ matrix.pyspark-version }}" --no-cache-dir
          echo "ARROW_PRE_0_15_IPC_FORMAT=1" >> $GITHUB_ENV
          echo "SPARK_LOCAL_IP=127.0.0.1" >> $GITHUB_ENV

      - name: Run Tests
        run: |
          make install
          pip install ".[test]"
          make test_spark

